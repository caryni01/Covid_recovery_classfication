---
title: "Covid Recovery Analysis - Figures and outputs"
author: "Cary Ni"
output: 
  pdf_document :
    latex_engine: xelatex
---

```{r setup, include=FALSE}
library(tidyverse)
library(AppliedPredictiveModeling)
library(caret)
library(glmnet)
library(mgcv)
library(earth)
library(gbm)
library(corrplot)
library(gridExtra)
knitr::opts_chunk$set(
  echo = TRUE,
  fig.align = 'center',
  out.width = "70%",
  strip.white = TRUE,
  warning = FALSE)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

```{r}
# load the external dataset 
load("recovery.rdata")
# change the variable type based on the reference
index_factor = c(3, 4, 5,  9, 10, 13, 14, 15)
index_numer = c(2, 6, 7, 8, 11, 12)
dat[, index_factor]= lapply(dat[, index_factor], as.factor)
# extract 2000+2000 samples for analysis
set.seed(2604)
dat_1 <- dat[sample(1:10000, 2000),]
set.seed(3508)
dat_2 <- dat[sample(1:10000, 2000),]
# merge the dataset for unique values
# create a new variable length_ind with 30 days as threshold 
dat = rbind(dat_1, dat_2) %>% 
  unique() %>% 
  mutate(
    length_ind = ifelse(recovery_time>30, "yes", "no"),
    length_ind = as.factor(length_ind)
  ) 

# seperate training set and test set
set.seed(2023)
train_row = createDataPartition(y = dat$recovery_time, p = 0.8, list = FALSE)
```

```{r train/test split for secondary analysis}
# create covariates matrix for training and test
predictors_train_new = model.matrix(length_ind ~ ., data = dat[train_row, -c(1,16)])[, -1]
predictors_test_new = model.matrix(length_ind ~ ., data = dat[-train_row, -c(1,16)])[, -1]
# create response vector for training and test
response_train_new = dat[train_row, -c(1,16)]$length_ind
response_test_new = dat[-train_row, -c(1,16)]$length_ind
```

### Adaptive boosting classfier

```{r}
ctrl_2 = trainControl(method = "cv",
                     classProbs = TRUE,
                     summaryFunction = twoClassSummary)
# set tunning parameters
# learning rate selection criterion : max(0.01, 0.1*(min(1, nl/10000)))
gbmA_grid = expand.grid(n.trees = c(seq(100, 1200, by = 100)),
                         interaction.depth = 1:3,
                         shrinkage = c(0.01, 0.05),
                         n.minobsinnode = 5)
set.seed(2)
gbmA_model = train(predictors_train_new, response_train_new,
                  tuneGrid = gbmA_grid,
                  trControl = ctrl_2,
                  method = "gbm",
                  distribution = "adaboost",
                  metric = "ROC",
                  verbose = FALSE)
ggplot(gbmA_model, highlight = TRUE)
```


### Models comparsion based on cross validation error

```{r}
# compare model performance through sampling method
resamp = resamples(list(
  lm = lm_model,
  enet = elnet_model,
  pls = pls_model,
  gam = gam_model,
  mars = mars_model,
  knn = knn_model,
  gbm = gbm_model
))
# plot resampling rmse
bwplot(resamp, metric = "RMSE")
summary(resamp) 
```

## Results

### Test Mean Squared Error
```{r}
# get test mse
predict_value = predict(gbm_model, newdata = predictors_test)
test_mse = mean((predict_value - response_test)^2)
test_mse %>% knitr::knit_print()
```

### Variable importance plots 

```{r}
par(mfrow = c(1, 1))
var_df = summary(gbm_model,
        cBars = 10,
        las = 2)  
var_df %>% 
  as.data.frame() %>% 
  select(-var) %>% 
  knitr::kable()
```

### Partial dependance plots

```{r}
p1 = pdp::partial(gbm_model, pred.var = c("bmi"), 
                  grid.resolution = 10) %>% autoplot()
p2 = pdp::partial(gbm_model, pred.var = c("vaccine1"), 
                  grid.resolution = 10) %>% autoplot()
p3 = pdp::partial(gbm_model, pred.var = c("severity1"), 
                  grid.resolution = 10) %>% autoplot()
p4 = pdp::partial(gbm_model, pred.var = c("age"), 
                  grid.resolution = 10) %>% autoplot()

grid.arrange(arrangeGrob(p1, p4, ncol = 2), arrangeGrob(p2, p3, ncol = 2))
```
